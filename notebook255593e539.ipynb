{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.7.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session",
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2022-11-14T19:58:28.389133Z",
     "iopub.execute_input": "2022-11-14T19:58:28.389528Z",
     "iopub.status.idle": "2022-11-14T19:58:28.418647Z",
     "shell.execute_reply.started": "2022-11-14T19:58:28.389393Z",
     "shell.execute_reply": "2022-11-14T19:58:28.417380Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Things to include in the notebook\n- Difference between training on the same dataset(s) and crossing dataset\n- Try to have it random if it should train on an image from MNIST or SVHN. \n- Try training with different types of preprocessing and data augmentation\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "# Loading the MNIST dataset\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\nfrom torchvision.transforms import ToTensor\nimport torchvision\nimport torch\n\n# These hyperparameters should be further tested\nbatch_size = 4\nnum_workers = 4\n\n\nmnist_train_dataset = torchvision.datasets.MNIST(root = \"data\", download = True, transform=ToTensor(), train=True)\nmnist_test_dataset = torchvision.datasets.MNIST(root = \"data\", download = True, transform=ToTensor(), train=False)\n\nmnist_train_data_loader = torch.utils.data.DataLoader(mnist_train_dataset,\n                                               batch_size = batch_size,\n                                               shuffle = True,\n                                               )\nmnist_test_data_loader = torch.utils.data.DataLoader(mnist_test_dataset,\n                                               batch_size = batch_size,\n                                               shuffle = True,\n                                               )",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-14T19:58:28.726740Z",
     "iopub.execute_input": "2022-11-14T19:58:28.727033Z",
     "iopub.status.idle": "2022-11-14T19:58:33.509707Z",
     "shell.execute_reply.started": "2022-11-14T19:58:28.727011Z",
     "shell.execute_reply": "2022-11-14T19:58:33.508512Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/9912422 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b60fdda8a644061bd26d13a5ed5ae7b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/28881 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "002b82c872e24ad8bfdd6865974b97fa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/1648877 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bce24c86c499444896c0cc37e2ce7549"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/4542 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "21cc05e7641e4dba987c8f891e2bd50a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Loading the SVHN dataset",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "svhn_train_dataset = torchvision.datasets.SVHN(root=\"data\", split='train', download=True, transform=ToTensor())\nsvhn_test_dataset = torchvision.datasets.SVHN(root=\"data\", split='test', download=True, transform=ToTensor())\n\nsvhn_train_data_loader = torch.utils.data.DataLoader(svhn_train_dataset,\n                                         batch_size = batch_size,\n                                         shuffle = True,\n                                         )\n\nsvhn_test_data_loader = torch.utils.data.DataLoader(svhn_test_dataset,\n                                         batch_size = batch_size,\n                                         shuffle = True,\n                                         )\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-14T19:58:33.511835Z",
     "iopub.execute_input": "2022-11-14T19:58:33.512498Z",
     "iopub.status.idle": "2022-11-14T19:59:11.826606Z",
     "shell.execute_reply.started": "2022-11-14T19:58:33.512465Z",
     "shell.execute_reply": "2022-11-14T19:59:11.825040Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to data/train_32x32.mat\n"
     ]
    },
    {
     "data": {
      "text/plain": "  0%|          | 0/182040794 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "063a83f956624b8fa5a19ccf1d8d48c8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/var/folders/hg/fn9xwmwn2cn9dbs9b732cgq00000gn/T/ipykernel_94547/3041274607.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0msvhn_train_dataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdatasets\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSVHN\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"data\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msplit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'train'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdownload\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtransform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mToTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0msvhn_test_dataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdatasets\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSVHN\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"data\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msplit\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m'test'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdownload\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtransform\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mToTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m svhn_train_data_loader = torch.utils.data.DataLoader(svhn_train_dataset,\n\u001B[1;32m      5\u001B[0m                                          \u001B[0mbatch_size\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/torchvision/datasets/svhn.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, root, split, transform, target_transform, download)\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mdownload\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 69\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdownload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     70\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     71\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_integrity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/torchvision/datasets/svhn.py\u001B[0m in \u001B[0;36mdownload\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    125\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mdownload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    126\u001B[0m         \u001B[0mmd5\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit_list\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 127\u001B[0;31m         \u001B[0mdownload_url\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mroot\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmd5\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    128\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/torchvision/datasets/utils.py\u001B[0m in \u001B[0;36mdownload_url\u001B[0;34m(url, root, filename, md5, max_redirect_hops)\u001B[0m\n\u001B[1;32m    139\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m             \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Downloading \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0murl\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0;34m\" to \"\u001B[0m \u001B[0;34m+\u001B[0m \u001B[0mfpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 141\u001B[0;31m             \u001B[0m_urlretrieve\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfpath\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    142\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0murllib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0merror\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mURLError\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mOSError\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# type: ignore[attr-defined]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0murl\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;36m5\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"https\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/torchvision/datasets/utils.py\u001B[0m in \u001B[0;36m_urlretrieve\u001B[0;34m(url, filename, chunk_size)\u001B[0m\n\u001B[1;32m     33\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0murllib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murlopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murllib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m\"User-Agent\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mUSER_AGENT\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtotal\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlength\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpbar\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m                 \u001B[0;32mfor\u001B[0m \u001B[0mchunk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchunk_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mchunk\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m                         \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.9/site-packages/torchvision/datasets/utils.py\u001B[0m in \u001B[0;36m<lambda>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     33\u001B[0m         \u001B[0;32mwith\u001B[0m \u001B[0murllib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0murlopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murllib\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrequest\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mRequest\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0murl\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mheaders\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m{\u001B[0m\u001B[0;34m\"User-Agent\"\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mUSER_AGENT\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     34\u001B[0m             \u001B[0;32mwith\u001B[0m \u001B[0mtqdm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtotal\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlength\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpbar\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 35\u001B[0;31m                 \u001B[0;32mfor\u001B[0m \u001B[0mchunk\u001B[0m \u001B[0;32min\u001B[0m \u001B[0miter\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;32mlambda\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mresponse\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mchunk_size\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     36\u001B[0m                     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mchunk\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     37\u001B[0m                         \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001B[0m in \u001B[0;36mread\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    460\u001B[0m             \u001B[0;31m# Amount is given, implement using readinto\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    461\u001B[0m             \u001B[0mb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mbytearray\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mamt\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 462\u001B[0;31m             \u001B[0mn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadinto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    463\u001B[0m             \u001B[0;32mreturn\u001B[0m \u001B[0mmemoryview\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0mn\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtobytes\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    464\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/http/client.py\u001B[0m in \u001B[0;36mreadinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    504\u001B[0m         \u001B[0;31m# connection, and the user is reading more bytes than will be provided\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    505\u001B[0m         \u001B[0;31m# (for example, reading in 1k chunks)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 506\u001B[0;31m         \u001B[0mn\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfp\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreadinto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    507\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mn\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mb\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    508\u001B[0m             \u001B[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/Cellar/python@3.9/3.9.7/Frameworks/Python.framework/Versions/3.9/lib/python3.9/socket.py\u001B[0m in \u001B[0;36mreadinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    702\u001B[0m         \u001B[0;32mwhile\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    703\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 704\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_sock\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mrecv_into\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mb\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    705\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mtimeout\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    706\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_timeout_occurred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Visualizing the MNIST dataset",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "from matplotlib import pyplot as plt\n\nfigure = plt.figure(figsize =(8,8))\ncols, rows = 3, 3\n\nfor i in range(1, cols * rows + 1):\n    sample_idx = torch.randint(len(mnist_train_dataset), size=(1,)).item()\n    img, label = mnist_train_dataset[sample_idx]\n    ax = figure.add_subplot(rows, cols, i)\n    ax.set_title(label)\n    plt.axis(\"off\")\n    plt.imshow(img.squeeze())\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-14T19:59:11.828386Z",
     "iopub.execute_input": "2022-11-14T19:59:11.828797Z",
     "iopub.status.idle": "2022-11-14T19:59:12.213939Z",
     "shell.execute_reply.started": "2022-11-14T19:59:11.828765Z",
     "shell.execute_reply": "2022-11-14T19:59:12.212581Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Visualizing the SVHN dataset\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "figure = plt.figure(figsize =(8,8))\ncols, rows = 3, 3\n\nfor i in range(1, cols * rows + 1):\n    sample_idx = torch.randint(len(svhn_train_dataset), size=(1,)).item()\n    img, label = svhn_train_dataset[sample_idx]\n    img = img.permute(1, 2, 0)\n    ax1 = figure.add_subplot(rows, cols, i)\n    ax1.set_title(label)\n    plt.axis(\"off\")\n    plt.imshow(img.squeeze())\n\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-14T19:59:12.217060Z",
     "iopub.execute_input": "2022-11-14T19:59:12.217879Z",
     "iopub.status.idle": "2022-11-14T19:59:12.663413Z",
     "shell.execute_reply.started": "2022-11-14T19:59:12.217823Z",
     "shell.execute_reply": "2022-11-14T19:59:12.662230Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Creating 2d-array with all the tensors based on label",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import numpy as np\n\n\nmnist_arr = []\nsvhn_arr = []\n\nfor i in range(10):\n    mnist_arr.append([])\n    svhn_arr.append([])\n\nfor num, item in enumerate(svhn_train_dataset):\n    svhn_img = item[0].permute(1, 2, 0)\n    svhn_arr[item[1]].append(svhn_img)\n\nfor num, item in enumerate(mnist_train_dataset):    \n    mnist_arr[item[1]].append(item[0])\n\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-14T19:59:12.665087Z",
     "iopub.execute_input": "2022-11-14T19:59:12.665351Z",
     "iopub.status.idle": "2022-11-14T19:59:27.599513Z",
     "shell.execute_reply.started": "2022-11-14T19:59:12.665328Z",
     "shell.execute_reply": "2022-11-14T19:59:27.598207Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Inspecting images at same position",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import random\npos1 = random.randint(0, 9)\npos2 = random.randint(0,min(len(mnist_arr), len(svhn_arr)))\n\n\nfigure = plt.figure(figsize =(8,8))\nmnist_img = mnist_arr[pos1][pos2]\nsvhn_img = svhn_arr[pos1][pos2]\n\n\nax = figure.add_subplot(1, 2, 1)\nax.set_title(pos1)\nplt.axis(\"off\")\nplt.imshow(mnist_img.squeeze(), cmap=\"gray\")\nax = figure.add_subplot(1, 2, 2)\nax.set_title(pos1)\nplt.axis(\"off\")\nplt.imshow(svhn_img.squeeze())\n\nplt.show()\n\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-14T20:13:35.973251Z",
     "iopub.execute_input": "2022-11-14T20:13:35.973621Z",
     "iopub.status.idle": "2022-11-14T20:13:36.084239Z",
     "shell.execute_reply.started": "2022-11-14T20:13:35.973595Z",
     "shell.execute_reply": "2022-11-14T20:13:36.083348Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Visualizing the distribution of labels from both datasets",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\nlabels = np.arange(0, 10)\nlen_mnist = [0] * 10\nlen_svhn = [0] * 10\n\nfor i in range(10):\n    len_mnist[i] = len(mnist_arr[i])\n    len_svhn[i] = len(svhn_arr[i])\n    \nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots()\nrects1 = ax.bar(labels - width/2, len_mnist, width, label='MNIST')\nrects2 = ax.bar(labels + width/2, len_svhn, width, label='SVHN')\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Amount')\nax.set_title('Amount of images by label')\nax.set_xticks(labels, labels)\nax.legend()\n\nax.bar_label(rects1, padding=3)\nax.bar_label(rects2, padding=3)\n\nfig.tight_layout()\n\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-14T19:59:27.815117Z",
     "iopub.execute_input": "2022-11-14T19:59:27.815487Z",
     "iopub.status.idle": "2022-11-14T19:59:28.102379Z",
     "shell.execute_reply.started": "2022-11-14T19:59:27.815459Z",
     "shell.execute_reply": "2022-11-14T19:59:28.101373Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "# Data preprocessing - Exploration phase\n",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Grayscale\n\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import torchvision.transforms as T\nimport cv2 as cv\n\ntest_img_mnist = mnist_arr[0][0]\ntest_img_svhn = svhn_arr[0][0]\n\n\ntest_img_svhn = torch.movedim(test_img_svhn, 2, 0)\n\ngray_svhn = T.Grayscale()(test_img_svhn)\n\ngray_svhn2 = gray_svhn\n\n\ngray_svhn = torch.movedim(gray_svhn, 0, 2)\n\ngray_svhn2 = gray_svhn2.detach().numpy()\ngray_svhn2 = cv.normalize(gray_svhn2, None, alpha = 0, beta = 255, norm_type = cv.NORM_MINMAX, dtype = cv.CV_32F)\ngray_svhn2 = 255 - gray_svhn2\n\nfigure = plt.figure(figsize =(12,8))\nax = figure.add_subplot(2, 3, 1)\nplt.axis(\"off\")\nax.set_title(\"MNIST in grayscale\")\nplt.imshow(test_img_mnist.squeeze(), cmap=\"gray\")\n\nax = figure.add_subplot(2, 3, 2)\nplt.axis(\"off\")\nax.set_title(\"SVHN in grayscale\")\nplt.imshow(gray_svhn.squeeze(), cmap=\"gray\")\n\nax = figure.add_subplot(2, 3, 3)\nplt.axis(\"off\")\nax.set_title(\"SVHN in grayscale normalized similar to MNIST\")\nplt.imshow(gray_svhn2.squeeze(), cmap=\"gray\")\n\nplt.show()\n",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-14T20:10:59.522340Z",
     "iopub.execute_input": "2022-11-14T20:10:59.522672Z",
     "iopub.status.idle": "2022-11-14T20:10:59.691556Z",
     "shell.execute_reply.started": "2022-11-14T20:10:59.522648Z",
     "shell.execute_reply": "2022-11-14T20:10:59.690825Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## Threshold\n",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "\nsvhn_img = svhn_arr[1][0]\nmnist_img = mnist_arr[1][0]\n\nsvhn = svhn_img.detach().numpy()\nmnist = mnist_img.detach().numpy()\n\nsvhn_grey = cv.normalize(svhn, None, alpha = 0, beta = 255, norm_type = cv.NORM_MINMAX, dtype = cv.CV_32F)\nsvhn_grey = cv.cvtColor(svhn_grey, cv.COLOR_BGR2GRAY)\nsvhn_grey = svhn_grey.astype(np.uint8)\n\nsvhn_threshold = cv.adaptiveThreshold(svhn_grey, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY,11,2)\nsvhn_threshold = cv.bitwise_not(svhn_threshold)\n\nmnist = cv.normalize(mnist, None, alpha = 0, beta = 255, norm_type = cv.NORM_MINMAX, dtype = cv.CV_8UC1)\nmnist = mnist.astype(np.uint8)\n#mnist_threshold = cv.adaptiveThreshold(mnist, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY,11,2)\n\n\nfigure = plt.figure(figsize =(12,12))\n\nax = figure.add_subplot(2, 2, 1)\nax.set_title(\"Original\")\nplt.axis(\"off\")\nplt.imshow(svhn.squeeze(), cmap=\"gray\")\n\nax = figure.add_subplot(2, 2, 2)\nax.set_title(\"Adaptive threshold\")\nplt.axis(\"off\")\nplt.imshow(svhn_threshold.squeeze(), cmap=\"gray\")\n\nfigure.add_subplot(2, 2, 3)\nplt.axis(\"off\")\nplt.imshow(mnist_frame.squeeze(), cmap=\"gray\")\n\nfigure.add_subplot(2, 2, 4)\nplt.axis(\"off\")\n\nplt.show()",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-14T20:42:22.532711Z",
     "iopub.execute_input": "2022-11-14T20:42:22.533063Z",
     "iopub.status.idle": "2022-11-14T20:42:22.750454Z",
     "shell.execute_reply.started": "2022-11-14T20:42:22.533037Z",
     "shell.execute_reply": "2022-11-14T20:42:22.749818Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "image = svhn_arr[8][0]\n\nimage = image.detach().numpy()\nimage = cv.normalize(image, None, alpha = 0, beta = 255, norm_type = cv.NORM_MINMAX, dtype = cv.CV_32F)\nimage = cv.cvtColor(image, cv.COLOR_BGR2GRAY)\nimage = image.astype(np.uint8)\n\nimage2 = image \nimage4 = image\n\nimage = cv.equalizeHist(image)\nclahe = cv.createCLAHE(clipLimit=3.,)\nimage2 = clahe.apply(image2)\n\nimage3 = cv.adaptiveThreshold(image, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY,11,2)\nimage4 = cv.adaptiveThreshold(image4, 255, cv.ADAPTIVE_THRESH_MEAN_C, cv.THRESH_BINARY,11,2)\n\n\nfigure = plt.figure(figsize =(8,8))\n\nax = figure.add_subplot(2, 2, 1)\nax.set_title(\"EqualizeHist\")\nplt.axis(\"off\")\nplt.imshow(image.squeeze(), cmap=\"gray\")\nax = figure.add_subplot(2, 2, 2)\nax.set_title(\"CLAHE\")\nplt.axis(\"off\")\nplt.imshow(image2.squeeze(), cmap=\"gray\")\nax = figure.add_subplot(2, 2, 3)\nax.set_title(\"Adaptive Threshold + EqualizeHist\")\nplt.axis(\"off\")\nplt.imshow(image3.squeeze(), cmap=\"gray\")\nax = figure.add_subplot(2, 2, 4)\nax.set_title(\"Adaptive Threshold\")\nplt.axis(\"off\")\nplt.imshow(image4.squeeze(), cmap=\"gray\")",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-11-14T20:12:06.524716Z",
     "iopub.execute_input": "2022-11-14T20:12:06.525045Z",
     "iopub.status.idle": "2022-11-14T20:12:06.760376Z",
     "shell.execute_reply.started": "2022-11-14T20:12:06.525023Z",
     "shell.execute_reply": "2022-11-14T20:12:06.758780Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}